{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple copy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files_with_extension(source_directory, destination_directory, file_extension='', chunk_size=1000):\n",
    "    # Create the destination directory if it doesn't exist\n",
    "    os.makedirs(destination_directory, exist_ok=True)\n",
    "\n",
    "    # Use os.scandir() for efficient file listing\n",
    "    with os.scandir(source_directory) as entries:\n",
    "        # Filter files with the specified extension\n",
    "        files_list = sorted([entry.name for entry in entries if entry.is_file() and entry.name.endswith(file_extension)])\n",
    "\n",
    "    # Split the list of files into sublists, each containing chunk_size elements\n",
    "    file_chunks = [files_list[i * chunk_size:(i + 1) * chunk_size] for i in range((len(files_list) + chunk_size - 1) // chunk_size)]\n",
    "\n",
    "    # Copy files to destination directories\n",
    "    for i, files_chunk in enumerate(file_chunks):\n",
    "        dest_path = os.path.join(destination_directory, str(i))\n",
    "        os.makedirs(dest_path, exist_ok=True)\n",
    "\n",
    "        for file in files_chunk:\n",
    "            source_path = os.path.join(source_directory, file)\n",
    "            destination_path = os.path.join(dest_path, file)\n",
    "\n",
    "            try:\n",
    "                shutil.copy2(source_path, destination_path)  # Use shutil.copy2 to preserve metadata\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Warning: {source_path} not found. Skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    source_dir = '/home/acer/workspace/videos/src'\n",
    "    dest_dir = '/home/acer/workspace/videos/dest'\n",
    "    file_extension = '.jpg'  # Specify the desired file extension, or leave it as an empty string to include all files\n",
    "    copy_files_with_extension(source_dir, dest_dir, file_extension=file_extension, chunk_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced copy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "import hashlib\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_hash(file_path, block_size=65536):\n",
    "    hasher = hashlib.sha256()\n",
    "    with open(file_path, 'rb') as file:\n",
    "        buffer = file.read(block_size)\n",
    "        while len(buffer) > 0:\n",
    "            hasher.update(buffer)\n",
    "            buffer = file.read(block_size)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "def copy_file(source_path, destination_path, deduplicate=False, file_hashes=None):\n",
    "    if deduplicate:\n",
    "        source_hash = get_file_hash(source_path)\n",
    "        destination_hash = get_file_hash(destination_path) if os.path.exists(destination_path) else None\n",
    "\n",
    "        if source_hash == destination_hash:\n",
    "            logging.info(f\"File {source_path} is a duplicate. Skipped.\")\n",
    "            return\n",
    "\n",
    "    try:\n",
    "        shutil.copy2(source_path, destination_path)  # Use shutil.copy2 to preserve metadata\n",
    "        logging.info(f\"File {source_path} copied to {destination_path}\")\n",
    "    except FileNotFoundError:\n",
    "        logging.warning(f\"Warning: {source_path} not found. Skipped.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error copying {source_path} to {destination_path}: {e}\")\n",
    "\n",
    "def copy_files_with_extension(source_directory, destination_directory, file_extension='', chunk_size=1000, deduplicate=False, parallelism=1):\n",
    "    # Create the destination directory if it doesn't exist\n",
    "    os.makedirs(destination_directory, exist_ok=True)\n",
    "\n",
    "    # Use os.scandir() for efficient file listing and sort the files\n",
    "    with os.scandir(source_directory) as entries:\n",
    "        # Filter files with the specified extension and sort them\n",
    "        files_list = sorted([entry.name for entry in entries if entry.is_file() and entry.name.endswith(file_extension)])\n",
    "\n",
    "    # Split the list of files into sublists, each containing chunk_size elements\n",
    "    file_chunks = [files_list[i * chunk_size:(i + 1) * chunk_size] for i in range((len(files_list) + chunk_size - 1) // chunk_size)]\n",
    "\n",
    "    # Set up progress bar\n",
    "    progress_bar = tqdm(total=len(files_list), desc=\"Copying Files\")\n",
    "\n",
    "    # Use ThreadPoolExecutor for parallel processing\n",
    "    # with ThreadPoolExecutor(max_workers=os.cpu_count() or 1) as executor:\n",
    "    with ThreadPoolExecutor(max_workers=parallelism) as executor:\n",
    "        futures = set()\n",
    "        file_hashes = set()  # For deduplication\n",
    "\n",
    "        for i, files_chunk in enumerate(file_chunks):\n",
    "            dest_path = os.path.join(destination_directory, str(i))\n",
    "            os.makedirs(dest_path, exist_ok=True)\n",
    "\n",
    "            for file in files_chunk:\n",
    "                source_path = os.path.join(source_directory, file)\n",
    "                destination_path = os.path.join(dest_path, file)\n",
    "                futures.add(executor.submit(copy_file, source_path, destination_path, deduplicate, file_hashes))\n",
    "\n",
    "            # Wait for a subset of file copying tasks to complete before moving to the next chunk\n",
    "            if len(futures) >= parallelism:\n",
    "                for future in as_completed(futures):\n",
    "                    future.result()\n",
    "                    progress_bar.update(1)\n",
    "                futures.clear()\n",
    "\n",
    "        # Wait for the remaining file copying tasks to complete\n",
    "        for future in as_completed(futures):\n",
    "            future.result()\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    source_dir = '/home/acer/workspace/videos/src'\n",
    "    dest_dir = '/home/acer/workspace/videos/dest'\n",
    "    file_extension = '.jpg'  # Specify the desired file extension, or leave it as an empty string to include all files\n",
    "    copy_files_with_extension(source_dir, dest_dir, file_extension=file_extension, chunk_size=100, deduplicate=True, parallelism=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
