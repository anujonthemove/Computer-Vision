{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "class FaceAndEyeDetection(object):\n",
    "    def __init__(self, video_path, face_model_path, eye_model_path):\n",
    "        self.video_path = video_path\n",
    "        self.face_cascade_model = cv2.CascadeClassifier(face_model_path)\n",
    "        self.eye_model_model = cv2.CascadeClassifier(eye_model_path)\n",
    "\n",
    "    def detect_faces(self, gray):\n",
    "        faces = self.face_cascade_model.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(self.image, (x, y), (x+w, y+h), (255, 255, 0), 2)\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = self.image[y:y+h, x:x+w]\n",
    "\n",
    "            eyes = self.eye_model_model.detectMultiScale(roi_gray)\n",
    "            for (ex, ey, ew, eh) in eyes:\n",
    "                cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 127, 255), 2)\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        self.detect_faces(gray)\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        while True:\n",
    "            ret, self.image = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            self.process_frame(self.image)\n",
    "            cv2.imshow('image', self.image)\n",
    "            k = cv2.waitKey(1) & 0xff\n",
    "            if k == 27:  # Press 'Esc' to exit\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def wrapper(video_path, face_model_path, eye_model_path):\n",
    "    model = FaceAndEyeDetection(video_path, face_model_path, eye_model_path)\n",
    "    model.run()\n",
    "\n",
    "\n",
    "def signal_handler(signum, frame):\n",
    "    print(\"Received Signal. Exiting gracefully.\")\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # very useful when this is run as a standalone .py file\n",
    "    signal.signal(signal.SIGINT, signal_handler)\n",
    "\n",
    "    face_model_path = './models/haarcascade_frontalface_default.xml'\n",
    "    eye_model_path = './models/haarcascade_eye.xml'\n",
    "\n",
    "    video_files = ['./test-videos/video-1.mp4', './test-videos/video-2.mp4', './test-videos/video-3.mp4', './test-videos/video-4.mp4']\n",
    "\n",
    "    jobs = []\n",
    "    for video_path in video_files:\n",
    "        p = multiprocessing.Process(target=wrapper, args=(video_path, face_model_path, eye_model_path))\n",
    "        jobs.append(p)\n",
    "        p.start()\n",
    "\n",
    "    for job in jobs:\n",
    "        job.join()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
