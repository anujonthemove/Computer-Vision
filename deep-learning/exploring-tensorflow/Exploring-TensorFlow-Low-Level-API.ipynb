{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring TensorFlow Low Level API\n",
    "* Simple CNN using [TensorFlow Low Level API](https://www.tensorflow.org/guide/low_level_intro)\n",
    "* __Naming your tensors (input/output) properly__\n",
    "* Different ways to save models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T03:00:26.841308Z",
     "start_time": "2019-05-08T03:00:24.959630Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from mnist import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST data\n",
    "* Using [MNIST data load util](https://github.com/anujonthemove/Computer-Vision-Playground/blob/master/utils/mnist.py)\n",
    "* __NOTE:__ In order to run this entire pipeline, please copy the `mnist.py` file from the `utils` directory \n",
    "and put it next to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T03:01:01.325084Z",
     "start_time": "2019-05-08T03:00:26.844293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading:  http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading:  http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading:  http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading:  http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "obj = mnist()\n",
    "X_train, y_train, X_test, y_test = obj.load_data()\n",
    "\n",
    "# split into validation and test set from the test set alone\n",
    "X_test, X_validation, y_test, y_validation = train_test_split(X_test, y_test, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T03:01:01.336272Z",
     "start_time": "2019-05-08T03:01:01.328397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Printing shapes of data ===\n",
      "\n",
      "Train data:       (60000, 32, 32, 1) (60000,)\n",
      "Test data:        (7500, 32, 32, 1) (7500,)\n",
      "Validation data:  (2500, 32, 32, 1) (2500,)\n"
     ]
    }
   ],
   "source": [
    "print('==== Printing shapes of data ===')\n",
    "print()\n",
    "print('Train data:      ', X_train.shape, y_train.shape)\n",
    "print('Test data:       ', X_test.shape, y_test.shape)\n",
    "print('Validation data: ', X_validation.shape, y_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network class for MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T03:01:02.052679Z",
     "start_time": "2019-05-08T03:01:01.340856Z"
    }
   },
   "outputs": [],
   "source": [
    "class MNISTClassification(object):\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, X_validation, y_validation, batch_size=128, \n",
    "                 epochs=10, model_dir = './models/mnist/lenet'):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.X_validation = X_validation\n",
    "        self.y_validation = y_validation\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        self.x = tf.placeholder(tf.float32, shape=[None, 32, 32, 1], name=\"input\")\n",
    "        self.y = tf.placeholder(tf.int32, shape=[None])\n",
    "        self.one_hot_y = tf.one_hot(self.y, 10)\n",
    "    \n",
    "        self.logits = self.LeNet5(self.x)\n",
    "        self.y_pred = tf.nn.softmax(self.logits, name=\"output\")\n",
    "        self.loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=self.one_hot_y, \n",
    "                                                                                 logits=self.logits))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        self.training_op = self.optimizer.minimize(self.loss_op)\n",
    "        self.correct_pred_op = tf.equal(tf.math.argmax(self.logits, 1), tf.math.argmax(self.one_hot_y, 1))\n",
    "        self.accuracy_op = tf.reduce_mean(tf.cast(self.correct_pred_op, tf.float32))\n",
    "        \n",
    "        config = tf.ConfigProto(device_count={'GPU':1, 'CPU':2})\n",
    "        config.gpu_options.allow_growth = True\n",
    "        config.gpu_options.per_process_gpu_memory_fraction = 0.75\n",
    "        \n",
    "        self.sess = tf.Session(config=config)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        self.model_dir = model_dir\n",
    "        if not os.path.exists(self.model_dir):\n",
    "            os.makedirs(self.model_dir)\n",
    "\n",
    "        \n",
    "    def LeNet5(self, x):\n",
    "    \n",
    "        ################   conv > relu > pool Block ####################\n",
    "        '''\n",
    "        convolution layer\n",
    "        Input: 32x32x1\n",
    "        Output: 28x28x6 - because we are taking 5x5 kernel\n",
    "\n",
    "        W' = [(W-F + 2P)/S]+1\n",
    "        where, \n",
    "        W' = dimension of output volume\n",
    "        W = dimension of input volume\n",
    "        F = kernel size\n",
    "        P = padding \n",
    "        S = stride \n",
    "\n",
    "        kernel size: 5x5x1, number of kernels: 6\n",
    "        '''\n",
    "        conv1_w = tf.Variable(tf.truncated_normal(shape=[5, 5, 1, 6], mean=0, stddev=0.1))\n",
    "        conv1_b = tf.Variable(tf.zeros(6)) \n",
    "        conv1 = tf.nn.conv2d(x, conv1_w, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "        '''\n",
    "        relu \n",
    "        size remains same\n",
    "        '''\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "        '''\n",
    "        pooling\n",
    "        Input: 28x28x6\n",
    "        Output: 14x14x6\n",
    "        '''\n",
    "        pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "\n",
    "        '''\n",
    "        convolution layer\n",
    "        Input: 14x14x6\n",
    "        Ouput: 10x10x16\n",
    "        '''\n",
    "        conv2_w = tf.Variable(tf.truncated_normal([5, 5, 6, 16], mean=0, stddev=0.1))\n",
    "        conv2_b = tf.Variable(tf.zeros(16))\n",
    "        conv2 = tf.nn.conv2d(pool1, conv2_w, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "\n",
    "        '''\n",
    "        relu \n",
    "        size remains same\n",
    "        '''\n",
    "        conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "\n",
    "        '''\n",
    "        pooling\n",
    "        Input: 10x10x16\n",
    "        Ouput: 5x5x16\n",
    "        '''\n",
    "        pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "\n",
    "        ############################################################################\n",
    "\n",
    "        ######################## reshape/flatten/fully connected layers ############\n",
    "\n",
    "        '''\n",
    "        flatten & fully connected layers\n",
    "        Input: 5x5x16\n",
    "        Intermediate (after reshape/flatten): 400 (5*5*16)\n",
    "        Output: 120\n",
    "        '''\n",
    "        fc1 = tf.reshape(pool2, [-1, 5*5*16])\n",
    "        fc1_w = tf.Variable(tf.truncated_normal(shape=(400, 120), mean=0, stddev=0.1))\n",
    "        fc1_b = tf.Variable(tf.zeros(120))\n",
    "        fc1 = tf.matmul(fc1, fc1_w) + fc1_b\n",
    "\n",
    "        '''\n",
    "        activation\n",
    "        '''\n",
    "        fc1 = tf.nn.relu(fc1)\n",
    "\n",
    "\n",
    "        '''\n",
    "        fully connected layer\n",
    "        '''\n",
    "        fc2_w = tf.Variable(tf.truncated_normal(shape=(120, 84), mean=0, stddev=0.1))\n",
    "        fc2_b = tf.Variable(tf.zeros(84))\n",
    "        fc2 = tf.matmul(fc1, fc2_w) + fc2_b\n",
    "\n",
    "\n",
    "        '''\n",
    "        activation\n",
    "        '''\n",
    "\n",
    "        fc2 = tf.nn.relu(fc2)\n",
    "\n",
    "        ####################################################################\n",
    "\n",
    "\n",
    "        '''\n",
    "        fully connected layer\n",
    "        '''\n",
    "\n",
    "        fc3_w = tf.Variable(tf.truncated_normal(shape=(84, 10), mean=0, stddev=0.1))\n",
    "        fc3_b = tf.Variable(tf.zeros(10))\n",
    "\n",
    "        logits = tf.matmul(fc2, fc3_w) + fc3_b\n",
    "\n",
    "        return logits\n",
    "    \n",
    "    def evaluate(self, X_tmp, y_tmp):\n",
    "        BATCH_SIZE = self.batch_size\n",
    "        num_examples = len(X_tmp)\n",
    "\n",
    "        total_accuracy = 0\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            batch_x, batch_y = X_tmp[offset:offset+BATCH_SIZE], y_tmp[offset:offset+BATCH_SIZE]\n",
    "            accuracy = self.sess.run(self.accuracy_op, feed_dict={self.x:batch_x, self.y:batch_y})\n",
    "            total_accuracy += (accuracy*len(batch_x))\n",
    "\n",
    "        return total_accuracy/num_examples\n",
    "\n",
    "    def release_session(self):\n",
    "        print('Releasing session ...')\n",
    "        print()\n",
    "        tf.reset_default_graph()\n",
    "        self.sess.close()\n",
    "        print('Done!')\n",
    "        \n",
    "        \n",
    "    def train(self, save_model=False):\n",
    "        BATCH_SIZE = self.batch_size\n",
    "        EPOCHS = self.epochs\n",
    "        num_examples = len(self.X_train)\n",
    "    \n",
    "        print('Training on dataset size: ', num_examples)\n",
    "        print()\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            print('===> Epoch: {}'.format(epoch+1))\n",
    "            x_tr, y_tr = shuffle(self.X_train, self.y_train)\n",
    "\n",
    "            for offset in range(0, num_examples, BATCH_SIZE):\n",
    "                batch_x, batch_y = x_tr[offset:offset + BATCH_SIZE], y_tr[offset:offset + BATCH_SIZE]\n",
    "                self.sess.run(self.training_op, feed_dict={self.x:batch_x, self.y:batch_y})\n",
    "\n",
    "            validaion_accuracy = self.evaluate(self.X_validation, self.y_validation)\n",
    "\n",
    "            print('===> Validation Accuracy: {:0.3f}'.format(validaion_accuracy))\n",
    "            print()\n",
    "        test_accuracy = self.evaluate(self.X_test, self.y_test)\n",
    "        print('===> Test Accuracy: {:0.3f}'.format(test_accuracy))\n",
    "        \n",
    "        \n",
    "    def save_model_using_saver_api(self, export_path, name, list_variables=False):\n",
    "        path_to_model = os.path.join(export_path, name)\n",
    "        saver = tf.train.Saver(write_version=tf.train.SaverDef.V2)\n",
    "        if list_variables:\n",
    "            for i, var in enumerate(saver._var_list):\n",
    "                print('Var {}: {}'.format(i, var))\n",
    "        save_path = saver.save(self.sess, path_to_model+'.ckpt', global_step=self.epochs)\n",
    "        tf.train.write_graph(self.sess.graph.as_graph_def(), export_path, name=name+'.pbtxt', as_text=True)\n",
    "        print('saved model at: ', save_path)\n",
    "    \n",
    "    def save_model_using_SavedModelBuilder(self, export_path, list_nodes=False):\n",
    "        builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "            \n",
    "        # get input, output tensor names\n",
    "        x = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "        y = tf.get_default_graph().get_tensor_by_name(\"output:0\")\n",
    "        \n",
    "        signature = tf.saved_model.predict_signature_def(\n",
    "            inputs={'input': x}, outputs={'output': y}\n",
    "        )\n",
    "        \n",
    "        # using custom tag instead of: tags=[tf.saved_model.tag_constants.SERVING]\n",
    "        builder.add_meta_graph_and_variables(\n",
    "            sess=self.sess, tags=['serve'], signature_def_map={'predict': signature}\n",
    "        )\n",
    "        \n",
    "        builder.save()\n",
    "        \n",
    "        if list_nodes:\n",
    "            print([n.name for n in tf.get_default_graph().as_graph_def().node])\n",
    "            \n",
    "    def save_model_using_simple_save(self, export_path):\n",
    "        print('==== WARNING from TensorFlow ====')\n",
    "        print()\n",
    "        print('Source: https://www.tensorflow.org/api_docs/python/tf/saved_model/simple_save')\n",
    "        print('Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\\\n",
    "        Instructions for updating: This function will only be available through the v1 \\\n",
    "        compatibility library as tf.compat.v1.saved_model.simple_save.')\n",
    "        print()\n",
    "        # get input, output tensor names\n",
    "        x = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "        y = tf.get_default_graph().get_tensor_by_name(\"output:0\")\n",
    "        \n",
    "        tf.saved_model.simple_save(self.sess, export_path, inputs={\"input\": x},outputs={\"output\": y})\n",
    "            \n",
    "    def predict(self, X):\n",
    "        x = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "        y = tf.get_default_graph().get_tensor_by_name(\"output:0\")\n",
    "        y_prediction = self.sess.run(y, feed_dict={x: X})\n",
    "        y_pred_prime = np.argmax(y_prediction, axis=1)\n",
    "        return y_pred_prime\n",
    "    \n",
    "    \n",
    "    def display_nodes_and_ops(self, print_nodes=False):\n",
    "        if print_nodes:\n",
    "            for n in tf.get_default_graph().as_graph_def().node:\n",
    "                print(n.name)\n",
    "                \n",
    "    def display_image(self, idx, X_tmp):\n",
    "        if X_tmp.shape[1:] != (32, 32, 1):\n",
    "            print('Invalid shape image provided')\n",
    "        else:\n",
    "            image = X_tmp[idx].squeeze()\n",
    "            plt.title('Example %d: ' % (idx))\n",
    "            plt.imshow(image, cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T03:01:03.742714Z",
     "start_time": "2019-05-08T03:01:02.059286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/anuj/.virtualenvs/analytics-3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = MNISTClassification(X_train, y_train, X_test, y_test, X_validation, y_validation, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T03:01:03.964407Z",
     "start_time": "2019-05-08T03:01:03.744407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.display_image(idx=5, X_tmp=X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T03:01:09.342127Z",
     "start_time": "2019-05-08T03:01:03.967399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on dataset size:  60000\n",
      "\n",
      "===> Epoch: 1\n",
      "===> Validation Accuracy: 0.968\n",
      "\n",
      "===> Test Accuracy: 0.964\n"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print all nodes in the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T03:01:09.347114Z",
     "start_time": "2019-05-08T03:01:09.344267Z"
    }
   },
   "outputs": [],
   "source": [
    "model.display_nodes_and_ops(print_nodes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. using tf.train.saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T03:01:09.767597Z",
     "start_time": "2019-05-08T03:01:09.348925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model at:  ./models/mnist/lenet/lenet.ckpt-1\n"
     ]
    }
   ],
   "source": [
    "model.save_model_using_saver_api(export_path='./models/mnist/lenet', name='lenet', list_variables=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. using  tf.saved_model.builder.SavedModelBuilder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T03:01:09.919747Z",
     "start_time": "2019-05-08T03:01:09.771219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/anuj/.virtualenvs/analytics-3/lib/python3.5/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./models/mnist/lenet/using_SavedModelBuilder/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "model.save_model_using_SavedModelBuilder(export_path='./models/mnist/lenet/using_SavedModelBuilder', \n",
    "                                         list_nodes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. using  tf.saved_model.simple_save - DEPRECATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T03:01:10.107302Z",
     "start_time": "2019-05-08T03:01:09.923223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== WARNING from TensorFlow ====\n",
      "\n",
      "Source: https://www.tensorflow.org/api_docs/python/tf/saved_model/simple_save\n",
      "Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.        Instructions for updating: This function will only be available through the v1         compatibility library as tf.compat.v1.saved_model.simple_save.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-4-69fbd771ef70>:235: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./models/mnist/lenet/using_simple_save/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "model.save_model_using_simple_save(export_path='./models/mnist/lenet/using_simple_save')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-08T03:01:10.118131Z",
     "start_time": "2019-05-08T03:01:10.110581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Releasing session ...\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model.release_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://medium.com/@lisulimowicz/tensorflow-cpus-and-gpus-configuration-9c223436d4ef\n",
    "* https://github.com/tensorspace-team/tensorspace/blob/master/docs/preprocess/TensorFlow/src_py/tensorflow_create_model.py\n",
    "* https://colab.research.google.com/drive/1CVm50PGE4vhtB5I_a_yc4h5F-itKOVL9#scrollTo=1w66ueiLlP0k\n",
    "* https://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/\n",
    "* https://medium.com/@jsflo.dev/saving-and-loading-a-tensorflow-model-using-the-savedmodel-api-17645576527"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
